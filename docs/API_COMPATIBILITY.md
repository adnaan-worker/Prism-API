# API å…¼å®¹æ€§åˆ†æä¸ä¿®å¤å»ºè®®

## æ¦‚è¿°

æœ¬æ–‡æ¡£åˆ†æ Prism API å¯¹å¤–æ¥å£ä¸ OpenAIã€Anthropicã€Gemini å®˜æ–¹ API çš„å…¼å®¹æ€§ï¼Œå¹¶æä¾›ä¿®å¤å»ºè®®ã€‚

## å½“å‰å®ç°é—®é¢˜

### 1. OpenAI æ ¼å¼ (`/v1/chat/completions`)

#### âœ… è¯·æ±‚æ ¼å¼ - å·²å¯¹é½
```json
{
  "model": "gpt-4",
  "messages": [{"role": "user", "content": "Hello"}],
  "temperature": 0.7,
  "max_tokens": 100,
  "stream": false
}
```

#### âš ï¸ å“åº”æ ¼å¼ - éƒ¨åˆ†ç¼ºå¤±
**å®˜æ–¹æ ‡å‡†å“åº”ï¼š**
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

**å½“å‰å®ç°ç¼ºå¤±å­—æ®µï¼š**
- âŒ `object` å­—æ®µï¼ˆåº”ä¸º "chat.completion"ï¼‰
- âŒ `created` å­—æ®µï¼ˆUnix æ—¶é—´æˆ³ï¼‰
- âŒ `finish_reason` å­—æ®µï¼ˆstop/length/content_filter/tool_callsï¼‰

#### âš ï¸ æµå¼å“åº”æ ¼å¼ - éœ€è¦éªŒè¯
**å®˜æ–¹ SSE æ ¼å¼ï¼š**
```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: [DONE]
```

**éœ€è¦ç¡®è®¤ï¼š**
- æ˜¯å¦åŒ…å« `object: "chat.completion.chunk"`
- æ˜¯å¦ä½¿ç”¨ `delta` è€Œä¸æ˜¯ `message`
- æ˜¯å¦ä»¥ `data: [DONE]` ç»“æŸ

---

### 2. Anthropic æ ¼å¼ (`/v1/messages`)

#### âœ… è¯·æ±‚æ ¼å¼ - å·²å¯¹é½
```json
{
  "model": "claude-3-opus-20240229",
  "max_tokens": 1024,
  "messages": [{"role": "user", "content": "Hello"}],
  "system": "You are a helpful assistant",
  "temperature": 0.7,
  "stream": false
}
```

**è¯·æ±‚å¤´è¦æ±‚ï¼š**
- âœ… `x-api-key` æˆ– `Authorization: Bearer`
- âœ… `anthropic-version: 2023-06-01`
- âœ… `content-type: application/json`

#### âš ï¸ å“åº”æ ¼å¼ - éƒ¨åˆ†ç¼ºå¤±
**å®˜æ–¹æ ‡å‡†å“åº”ï¼š**
```json
{
  "id": "msg_01XFDUDYJgAACzvnptvVoYEL",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Hello! How can I help you today?"
    }
  ],
  "model": "claude-3-opus-20240229",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 10,
    "output_tokens": 20
  }
}
```

**å½“å‰å®ç°é—®é¢˜ï¼š**
- âœ… `type` å­—æ®µæ­£ç¡®
- âœ… `content` æ•°ç»„æ ¼å¼æ­£ç¡®
- âŒ ç¼ºå°‘ `stop_sequence` å­—æ®µ
- âš ï¸ `stop_reason` å¯èƒ½å€¼ä¸å®Œæ•´ï¼ˆåº”åŒ…å«ï¼šend_turn, max_tokens, stop_sequence, tool_useï¼‰

#### âš ï¸ æµå¼å“åº”æ ¼å¼ - éœ€è¦éªŒè¯
**å®˜æ–¹ SSE æ ¼å¼ï¼š**
```
event: message_start
data: {"type":"message_start","message":{"id":"msg_123","type":"message","role":"assistant","content":[],"model":"claude-3-opus-20240229","stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"output_tokens":0}}}

event: content_block_start
data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}

event: content_block_delta
data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Hello"}}

event: content_block_stop
data: {"type":"content_block_stop","index":0}

event: message_delta
data: {"type":"message_delta","delta":{"stop_reason":"end_turn","stop_sequence":null},"usage":{"output_tokens":20}}

event: message_stop
data: {"type":"message_stop"}
```

**éœ€è¦ç¡®è®¤ï¼š**
- Anthropic ä½¿ç”¨ `event:` å’Œ `data:` çš„ SSE æ ¼å¼
- éœ€è¦å¤šä¸ªäº‹ä»¶ç±»å‹ï¼ˆmessage_start, content_block_delta, message_stop ç­‰ï¼‰

---

### 3. Gemini æ ¼å¼ (`/v1/models/{model}:generateContent`)

#### âœ… è¯·æ±‚æ ¼å¼ - å·²å¯¹é½
```json
{
  "contents": [
    {
      "role": "user",
      "parts": [{"text": "Hello"}]
    }
  ],
  "generationConfig": {
    "temperature": 0.7,
    "maxOutputTokens": 100
  }
}
```

**URL æ ¼å¼ï¼š**
- âœ… `/v1/models/{model}:generateContent?key={api_key}`

#### âš ï¸ å“åº”æ ¼å¼ - éƒ¨åˆ†ç¼ºå¤±
**å®˜æ–¹æ ‡å‡†å“åº”ï¼š**
```json
{
  "candidates": [
    {
      "content": {
        "parts": [{"text": "Hello! How can I help you?"}],
        "role": "model"
      },
      "finishReason": "STOP",
      "index": 0,
      "safetyRatings": [
        {
          "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
          "probability": "NEGLIGIBLE"
        }
      ]
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 5,
    "candidatesTokenCount": 10,
    "totalTokenCount": 15
  },
  "modelVersion": "gemini-1.5-pro-001"
}
```

**å½“å‰å®ç°ç¼ºå¤±å­—æ®µï¼š**
- âŒ `safetyRatings` æ•°ç»„ï¼ˆå®‰å…¨è¯„çº§ï¼‰
- âŒ `modelVersion` å­—æ®µ
- âš ï¸ `finishReason` å¯èƒ½å€¼ä¸å®Œæ•´ï¼ˆåº”åŒ…å«ï¼šSTOP, MAX_TOKENS, SAFETY, RECITATION, OTHERï¼‰

#### âš ï¸ æµå¼å“åº”æ ¼å¼ - éœ€è¦éªŒè¯
**å®˜æ–¹ SSE æ ¼å¼ï¼š**
```
data: {"candidates":[{"content":{"parts":[{"text":"Hello"}],"role":"model"},"finishReason":"STOP","index":0}],"usageMetadata":{"promptTokenCount":5,"candidatesTokenCount":1,"totalTokenCount":6}}

data: {"candidates":[{"content":{"parts":[{"text":"!"}],"role":"model"},"finishReason":"STOP","index":0}],"usageMetadata":{"promptTokenCount":5,"candidatesTokenCount":2,"totalTokenCount":7}}
```

**éœ€è¦ç¡®è®¤ï¼š**
- æµå¼ URL åº”ä¸º `/v1/models/{model}:streamGenerateContent?key={api_key}&alt=sse`
- æ¯ä¸ª chunk éƒ½æ˜¯å®Œæ•´çš„ JSON å¯¹è±¡

---

## ä¿®å¤ä¼˜å…ˆçº§

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå½±å“å…¼å®¹æ€§ï¼‰

1. **OpenAI å“åº”æ ¼å¼è¡¥å…¨**
   - æ·»åŠ  `object` å­—æ®µ
   - æ·»åŠ  `created` å­—æ®µ
   - æ·»åŠ  `finish_reason` å­—æ®µ

2. **Anthropic æµå¼å“åº”æ ¼å¼**
   - å®ç°å®Œæ•´çš„äº‹ä»¶æµæ ¼å¼ï¼ˆmessage_start, content_block_delta ç­‰ï¼‰
   - å½“å‰å¯èƒ½åªæ˜¯ç›´æ¥é€ä¼ ï¼Œéœ€è¦éªŒè¯

3. **Gemini æµå¼å“åº” URL**
   - ç¡®è®¤ä½¿ç”¨ `:streamGenerateContent` è€Œä¸æ˜¯ `:generateContent`

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆå¢å¼ºå…¼å®¹æ€§ï¼‰

4. **é”™è¯¯å“åº”æ ¼å¼å¯¹é½**
   - OpenAI: `{"error": {"message": "...", "type": "...", "code": "..."}}`
   - Anthropic: `{"type": "error", "error": {"type": "...", "message": "..."}}`
   - Gemini: `{"error": {"code": 400, "message": "...", "status": "INVALID_ARGUMENT"}}`

5. **æ·»åŠ ç¼ºå¤±çš„å¯é€‰å­—æ®µ**
   - Anthropic: `stop_sequence`
   - Gemini: `safetyRatings`, `modelVersion`

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆå®Œå–„åŠŸèƒ½ï¼‰

6. **æ”¯æŒæ›´å¤šè¯·æ±‚å‚æ•°**
   - OpenAI: `top_p`, `n`, `presence_penalty`, `frequency_penalty`
   - Anthropic: `top_p`, `top_k`, `metadata`
   - Gemini: `topP`, `topK`, `stopSequences`, `safetySettings`

---

## å»ºè®®çš„ä¿®å¤æ­¥éª¤

### Step 1: ä¿®å¤ OpenAI å“åº”æ ¼å¼

ä¿®æ”¹ `backend/internal/adapter/openai_adapter.go`:

```go
func (a *OpenAIAdapter) convertResponse(resp *openAIResponse) *ChatResponse {
    choices := make([]ChatChoice, len(resp.Choices))
    for i, choice := range resp.Choices {
        choices[i] = ChatChoice{
            Index:        choice.Index,
            Message:      choice.Message,
            FinishReason: choice.FinishReason, // æ·»åŠ æ­¤å­—æ®µ
        }
    }

    return &ChatResponse{
        ID:      resp.ID,
        Object:  "chat.completion", // æ·»åŠ æ­¤å­—æ®µ
        Created: resp.Created,      // æ·»åŠ æ­¤å­—æ®µ
        Model:   resp.Model,
        Choices: choices,
        Usage: UsageInfo{
            PromptTokens:     resp.Usage.PromptTokens,
            CompletionTokens: resp.Usage.CompletionTokens,
            TotalTokens:      resp.Usage.TotalTokens,
        },
    }
}
```

### Step 2: ä¿®å¤ proxy_handler.go çš„å“åº”è½¬æ¢

ç¡®ä¿ `ChatCompletions` å¤„ç†å™¨ç›´æ¥è¿”å› OpenAI æ ¼å¼ï¼Œä¸åšé¢å¤–è½¬æ¢ã€‚

### Step 3: éªŒè¯æµå¼å“åº”æ ¼å¼

æµ‹è¯•ä¸‰å®¶å‚å•†çš„æµå¼å“åº”æ˜¯å¦ç¬¦åˆå®˜æ–¹æ ¼å¼ã€‚

### Step 4: ç»Ÿä¸€é”™è¯¯å“åº”æ ¼å¼

ä¸ºæ¯ä¸ªå‚å•†å®ç°ç¬¦åˆå…¶æ ‡å‡†çš„é”™è¯¯å“åº”æ ¼å¼ã€‚

---

## æµ‹è¯•å»ºè®®

### 1. å…¼å®¹æ€§æµ‹è¯•

ä½¿ç”¨å®˜æ–¹ SDK æµ‹è¯•ï¼š

```python
# OpenAI SDK
import openai
client = openai.OpenAI(
    api_key="your-prism-api-key",
    base_url="http://localhost:8080/v1"
)
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}]
)

# Anthropic SDK
import anthropic
client = anthropic.Anthropic(
    api_key="your-prism-api-key",
    base_url="http://localhost:8080"
)
message = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello"}]
)

# Google Gemini SDK
import google.generativeai as genai
genai.configure(
    api_key="your-prism-api-key",
    transport="rest",
    client_options={"api_endpoint": "http://localhost:8080"}
)
model = genai.GenerativeModel('gemini-pro')
response = model.generate_content("Hello")
```

### 2. å­—æ®µéªŒè¯æµ‹è¯•

ç¼–å†™æµ‹è¯•ç”¨ä¾‹éªŒè¯æ‰€æœ‰å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨ã€‚

### 3. æµå¼å“åº”æµ‹è¯•

æµ‹è¯• SSE æµå¼å“åº”çš„æ ¼å¼å’Œäº‹ä»¶é¡ºåºã€‚

---

## å‚è€ƒæ–‡æ¡£

- [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat/create)
- [Anthropic Messages API](https://docs.anthropic.com/en/api/messages)
- [Google Gemini API](https://ai.google.dev/gemini-api/docs/text-generation)
